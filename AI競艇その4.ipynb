{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNup9DaCdwKVsE1ocm2GGqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kingfinalweapon/kings/blob/master/AI%E7%AB%B6%E8%89%87%E3%81%9D%E3%81%AE4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzvQR3KsiyQ8",
        "outputId": "79f0d788-b2dd-4a9c-b2ad-61ed70f61abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mojimoji\n",
            "  Downloading mojimoji-0.0.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mojimoji\n",
            "Successfully installed mojimoji-0.0.12\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install mojimoji\n",
        "import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mojimoji"
      ],
      "metadata": {
        "id": "VcxLizzDlKM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストファイルを読み込み、会場ごとのデータにテキストを区切って出力\n",
        "\n",
        "\n",
        "\n",
        "f = open(f'B210801.TXT', 'r', encoding='shift-jis')\n",
        "Lines = [l.strip().replace('\\u3000', '') for l in f]\n",
        "# テキストファイル中の前後の空白と余白を削除\n",
        "Lines = [mojimoji.zen_to_han(l, kana=False) for l in Lines][1:-1]\n",
        "# 文字の全角を半角に高速にする\n",
        "lines_by_plc = {}\n",
        "for l in Lines:\n",
        "    if 'BGN' in l:\n",
        "        place_cd = int(l[:-4])\n",
        "        # l=24BBGM→place_cd→24\n",
        "\n",
        "        lines = []\n",
        "    elif 'END' in l:\n",
        "        lines_by_plc[place_cd] = lines\n",
        "        # 辞書型で保存している{24:[番組でーた]}\n",
        "\n",
        "    else:\n",
        "        lines.append(l)\n",
        "type(lines_by_plc)"
      ],
      "metadata": {
        "id": "t0nqneP_i9Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    info_cols = ['title', 'day', 'date', 'place_cd', 'place']\n",
        "    race_cols = ['race_no', 'race_type', 'distance', 'deadline']\n",
        "    keys = ['toban', 'name', 'area', 'class', 'age', 'weight',\n",
        "            'glob_win', 'glob_in2', 'loc_win', 'loc_in2',\n",
        "            'moter_no', 'moter_in2', 'boat_no', 'boat_in2']\n",
        "    racer_cols = [f'{k}_{i}' for k in keys for i in range(1, 7)]\n",
        "    # keysについて1～6を振る　toban=toban_1 toban_2\n",
        "    cols = info_cols + race_cols + racer_cols\n",
        "    # カラムを作成"
      ],
      "metadata": {
        "id": "zuZ5QDFrBKeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    for place_cd, lines in read_file('racelists', date).items():\n",
        "        min_lines = 11\n",
        "        if len(lines) < min_lines:\n",
        "            continue\n",
        "        title = lines[4]\n",
        "        day = int(re.findall('第(\\d)日', lines[6].replace(' ', ''))[0])\n",
        "        place = place_mapper[place_cd]\n",
        "        info = {k: v for k, v in zip(\n",
        "            info_cols, [title, day, date, place_cd, place])}\n",
        "\n",
        "        head_list = []\n",
        "        race_no = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "uYpwgwCCC3Ik",
        "outputId": "cbc59054-c807-40ed-f286-54a5931f290e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-77dff71fddf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m info = {k: v for k, v in zip(\n\u001b[0;32m----> 2\u001b[0;31m             info_cols, [title, day, date, place_cd, place])}\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'title' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 圧縮ファイルをウェブからダウンロードし解凍 >> テキストファイルを保存\n",
        "def download_file(obj, date):\n",
        "    \"\"\"\n",
        "    obj (str): 'racelists' or 'results'\n",
        "    \"\"\"\n",
        "    date = str(pd.to_datetime(date).date())\n",
        "    ymd = date.replace('-', '')\n",
        "    S, s = ('K', 'k') if obj == 'results' else ('B', 'b')\n",
        "    if os.path.exists(f'downloads/{obj}/{ymd}.txt'):\n",
        "        return\n",
        "    else:\n",
        "        os.makedirs(f'downloads/{obj}', exist_ok=True)\n",
        "        try:\n",
        "            url_t = f'http://www1.mbrace.or.jp/od2/{S}/'\n",
        "            url_b = f'{ymd[:-2]}/{s}{ymd[2:]}.lzh'\n",
        "            wget.download(url_t + url_b, f'downloads/{obj}/{ymd}.lzh')\n",
        "            archive = LhaFile(f'downloads/{obj}/{ymd}.lzh')\n",
        "            d = archive.read(archive.infolist()[0].filename)\n",
        "            open(f'downloads/{obj}/{ymd}.txt', 'wb').write(d)\n",
        "            subprocess.run(['rm', f'downloads/{obj}/{ymd}.lzh'])\n",
        "        except urllib.request.HTTPError:\n",
        "            print(f'There are no data for {date}')\n",
        "# テキストファイルを読み込み、会場ごとのデータにテキストを区切って出力\n",
        "def read_file(obj, date):\n",
        "    \"\"\"\n",
        "    obj (str): 'racelists' or 'results'\n",
        "    \"\"\"\n",
        "    date = str(pd.to_datetime(date).date())\n",
        "    ymd = date.replace('-', '')\n",
        "    f = open(f'downloads/{obj}/{ymd}.txt', 'r', encoding='shift-jis')\n",
        "    Lines = [l.strip().replace('\\u3000', '') for l in f]\n",
        "    Lines = [mojimoji.zen_to_han(l, kana=False) for l in Lines][1:-1]\n",
        "    lines_by_plc = {}\n",
        "    for l in Lines:\n",
        "        if 'BGN' in l:\n",
        "            place_cd = int(l[:-4])\n",
        "            lines = []\n",
        "        elif 'END' in l:\n",
        "            lines_by_plc[place_cd] = lines\n",
        "        else:\n",
        "            lines.append(l)\n",
        "    return lines_by_plc\n",
        "# 出走表ファイルのフォーマットを解析し、いい感じにテーブルに変形して出力\n",
        "place_mapper = {\n",
        "    1: '桐生', 2: '戸田', 3: '江戸川', 4: '平和島', 5: '多摩川',\n",
        "    6: '浜名湖', 7: '蒲郡', 8: '常滑', 9: '津', 10: '三国',\n",
        "    11: '琵琶湖', 12: '住之江', 13: '尼崎', 14: '鳴門', 15: '丸亀',\n",
        "    16: '児島', 17: '宮島', 18: '徳山', 19: '下関', 20: '若松',\n",
        "    21: '芦屋', 22: '福岡', 23: '唐津', 24: '大村'\n",
        "}\n",
        "\n",
        "def get_racelists(date):\n",
        "    info_cols = ['title', 'day', 'date', 'place_cd', 'place']\n",
        "    race_cols = ['race_no', 'race_type', 'distance', 'deadline']\n",
        "    keys = ['toban', 'name', 'area', 'class', 'age', 'weight',\n",
        "            'glob_win', 'glob_in2', 'loc_win', 'loc_in2',\n",
        "            'moter_no', 'moter_in2', 'boat_no', 'boat_in2']\n",
        "    racer_cols = [f'{k}_{i}' for k in keys for i in range(1, 7)]\n",
        "    cols = info_cols + race_cols + racer_cols\n",
        "\n",
        "    stack = []\n",
        "    date = str(pd.to_datetime(date).date())\n",
        "    for place_cd, lines in read_file('racelists', date).items():\n",
        "        min_lines = 11\n",
        "        if len(lines) < min_lines:\n",
        "            continue\n",
        "        title = lines[4]\n",
        "        day = int(re.findall('第(\\d)日', lines[6].replace(' ', ''))[0])\n",
        "        place = place_mapper[place_cd]\n",
        "        info = {k: v for k, v in zip(\n",
        "            info_cols, [title, day, date, place_cd, place])}\n",
        "\n",
        "        head_list = []\n",
        "        race_no = 1\n",
        "        for i, l in enumerate(lines[min_lines:]):\n",
        "            if f'{race_no}R' in l:\n",
        "                head_list.append(min_lines + i)\n",
        "                race_no += 1\n",
        "        for race_no, head in enumerate(head_list, 1):\n",
        "            try:\n",
        "                race_type = lines[head].split()[1]\n",
        "                distance = int(re.findall('H(\\d*)m', lines[head])[0])\n",
        "                deadline = re.findall('電話投票締切予定(\\d*:\\d*)', lines[head])[0]\n",
        "                arr = []\n",
        "                for l in lines[head + 5: head + 11]:\n",
        "                    split = re.findall('\\d \\d{4}.*\\d\\d\\.\\\\d\\d', l)[0].split()\n",
        "                    bno = [0]\n",
        "                    name, area, cls1 = [e for e in re.findall(\n",
        "                        '[^\\d]*', split[1]) if e != '']\n",
        "                    toban, age, wght, cls2 = [e for e in re.findall(\n",
        "                        '[\\d]*', split[1]) if e != '']\n",
        "                    tmp = [toban, name, area, cls1 + cls2, age, wght] + split[2:10]\n",
        "                    if len(tmp) == 14:\n",
        "                        arr.append(tmp)\n",
        "                    else:\n",
        "                        continue\n",
        "                if len(arr) == 6:\n",
        "                    dic = info.copy()\n",
        "                    dic.update(zip(race_cols, [race_no, race_type, distance, deadline]))\n",
        "                    dic.update(dict(zip(racer_cols, np.array(arr).T.reshape(-1))))\n",
        "                    stack.append(dic)\n",
        "            except IndexError:\n",
        "                continue\n",
        "            except ValueError:\n",
        "                continue\n",
        "    if len(stack) > 0:\n",
        "        df = pd.DataFrame(stack)[cols].dropna()\n",
        "        return df.astype(get_dtype('racelists'))\n",
        "    else:\n",
        "        return None\n",
        "# 結果ファイルのフォーマットを解析し、いい感じにテーブルに変形して出力\n",
        "def get_results(date):\n",
        "    conv_racetime = lambda x: np.nan if x == '.' else\\\n",
        "        sum([w * float(v) for w, v in zip((60, 1, 1/10), x.split('.'))])\n",
        "    info_cols = ['title', 'day', 'date', 'place_cd', 'place']\n",
        "    race_cols = ['race_no', 'race_type', 'distance']\n",
        "    keys = ['toban', 'name', 'moter_no', 'boat_no',\n",
        "            'ET', 'SC', 'ST', 'RT', 'position']\n",
        "    racer_cols = [f'{k}_{i}' for k in keys for i in range(1, 7)]\n",
        "    res_cols = []\n",
        "    for k in ('tkt', 'odds', 'poprank'):\n",
        "        for type_ in ('1t', '1f1', '1f2', '2t', '2f',\n",
        "                      'w1', 'w2', 'w3', '3t', '3f'):\n",
        "            if (k == 'poprank') & (type_ in ('1t', '1f1', '1f2')):\n",
        "                pass\n",
        "            else:\n",
        "                res_cols.append(f'{k}_{type_}')\n",
        "    res_cols.append('win_method')\n",
        "    cols = info_cols + race_cols + racer_cols + res_cols\n",
        "\n",
        "    stack = []\n",
        "    date = str(pd.to_datetime(date).date())\n",
        "    for place_cd, lines in read_file('results', date).items():\n",
        "        min_lines = 26\n",
        "        if len(lines) < min_lines:\n",
        "            continue\n",
        "        title = lines[4]\n",
        "        day = int(re.findall('第(\\d)日', lines[6].replace(' ', ''))[0])\n",
        "        place = place_mapper[place_cd]\n",
        "        info = {k: v for k, v in zip(\n",
        "            info_cols, [title, day, date, place_cd, place])}\n",
        "\n",
        "        head_list = []\n",
        "        race_no = 1\n",
        "        for i, l in enumerate(lines[min_lines:]):\n",
        "            if f'{race_no}R' in l:\n",
        "                head_list.append(min_lines + i)\n",
        "                race_no += 1\n",
        "        for race_no, head in enumerate(head_list, 1):\n",
        "            try:\n",
        "                race_type = lines[head].split()[1]\n",
        "                distance = int(re.findall('H(\\d*)m', lines[head])[0])\n",
        "                win_method = lines[head + 1].split()[-1]\n",
        "                _, tkt_1t, pb_1t = lines[head + 10].split()\n",
        "                _, tkt_1f1, pb_1f1, tkt_1f2, pb_1f2 = lines[head + 11].split()\n",
        "                _, tkt_2t, pb_2t, _, pr_2t = lines[head + 12].split()\n",
        "                _, tkt_2f, pb_2f, _, pr_2f = lines[head + 13].split()\n",
        "                _, tkt_w1, pb_w1, _, pr_w1 = lines[head + 14].split()\n",
        "                tkt_w2, pb_w2, _, pr_w2 = lines[head + 15].split()\n",
        "                tkt_w3, pb_w3, _, pr_w3 = lines[head + 16].split()\n",
        "                _, tkt_3t, pb_3t, _, pr_3t = lines[head + 17].split()\n",
        "                _, tkt_3f, pb_3f, _, pr_3f = lines[head + 18].split()\n",
        "                race_vals = [race_no, race_type, distance]\n",
        "                res_vals = [\n",
        "                    tkt_1t, tkt_1f1, tkt_1f2, tkt_2t, tkt_2f,\n",
        "                    tkt_w1, tkt_w2, tkt_w3, tkt_3t, tkt_3f,\n",
        "                    pb_1t, pb_1f1, pb_1f2, pb_2t, pb_2f,\n",
        "                    pb_w1, pb_w2, pb_w3, pb_3t, pb_3f,\n",
        "                    pr_2t, pr_2f, pr_w1, pr_w2, pr_w3,\n",
        "                    pr_3t, pr_3f, win_method\n",
        "                ]\n",
        "                dic = info.copy()\n",
        "                dic.update(dict(zip(race_cols, race_vals)))\n",
        "                dic.update(dict(zip(res_cols, res_vals)))\n",
        "                dic = {k: float(v) / 100 if 'odds' in k else v\n",
        "                       for k, v in dic.items()}\n",
        "                for i in range(6):\n",
        "                    bno, *vals = lines[head + 3 + i].split()[1:10]\n",
        "                    vals.append(i + 1)\n",
        "                    keys = ['toban', 'name', 'moter_no', 'boat_no',\n",
        "                            'ET', 'SC', 'ST', 'RT', 'position']\n",
        "                    dic.update(zip([f'{k}_{bno}' for k in keys], vals))\n",
        "                stack.append(dic)\n",
        "            except IndexError:\n",
        "                continue\n",
        "            except ValueError:\n",
        "                continue\n",
        "    if len(stack) > 0:\n",
        "        df = pd.DataFrame(stack)[cols].dropna(how='all')\n",
        "        repl_mapper = {'K': np.nan, '.': np.nan}\n",
        "        for i in range(1, 7):\n",
        "            df[f'ET_{i}'] = df[f'ET_{i}'].replace(repl_mapper)\n",
        "            df[f'ST_{i}'] = df[f'ST_{i}'].replace(repl_mapper)\\\n",
        "                .str.replace('F', '-').str.replace('L', '1')\n",
        "            df[f'RT_{i}'] = df[f'RT_{i}'].map(conv_racetime)\n",
        "        waku = np.array([('{}'*6).format(*v) for v in df[\n",
        "            [f'SC_{i}' for i in range(1, 7)]].values])\n",
        "        df['wakunari'] = np.where(waku == '123456', 1, 0)\n",
        "        df = df.replace({'K': np.nan})\n",
        "        return df.astype(get_dtype('results'))\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "f2uQhql0GdLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7k6yH1gLi9BZ"
      }
    }
  ]
}